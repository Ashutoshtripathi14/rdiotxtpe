{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Multinomial Naive Bayes\n",
      "[[308 109]\n",
      " [  8  81]]\n",
      "0.7687747035573123\n",
      "0.5806451612903226\n",
      "0.4263157894736842\n",
      "0.9101123595505618\n",
      "-------------------------------\n",
      "Bernoulli Naive Bayes\n",
      "[[288 129]\n",
      " [ 25  64]]\n",
      "0.6956521739130435\n",
      "0.45390070921985815\n",
      "0.3316062176165803\n",
      "0.7191011235955056\n",
      "-------------------------------\n",
      "Linear SVC\n",
      "[[414   3]\n",
      " [  1  88]]\n",
      "0.9920948616600791\n",
      "0.9777777777777779\n",
      "0.967032967032967\n",
      "0.9887640449438202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "C-Support Vector Classification \n",
      "[[417   0]\n",
      " [ 85   4]]\n",
      "0.8320158102766798\n",
      "0.08602150537634408\n",
      "1.0\n",
      "0.0449438202247191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from math import *\n",
    "from numpy import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "import os\n",
    "import string\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score,recall_score,precision_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "def striprtf(text):\n",
    "   pattern = re.compile(r\"\\\\([a-z]{1,32})(-?\\d{1,10})?[ ]?|\\\\'([0-9a-f]{2})|\\\\([^a-z])|([{}])|[\\r\\n]+|(.)\", re.I)\n",
    "   # control words which specify a \"destionation\".\n",
    "   destinations = frozenset((\n",
    "      'aftncn','aftnsep','aftnsepc','annotation','atnauthor','atndate','atnicn','atnid',\n",
    "      'atnparent','atnref','atntime','atrfend','atrfstart','author','background',\n",
    "      'bkmkend','bkmkstart','blipuid','buptim','category','colorschememapping',\n",
    "      'colortbl','comment','company','creatim','datafield','datastore','defchp','defpap',\n",
    "      'do','doccomm','docvar','dptxbxtext','ebcend','ebcstart','factoidname','falt',\n",
    "      'fchars','ffdeftext','ffentrymcr','ffexitmcr','ffformat','ffhelptext','ffl',\n",
    "      'ffname','ffstattext','field','file','filetbl','fldinst','fldrslt','fldtype',\n",
    "      'fname','fontemb','fontfile','fonttbl','footer','footerf','footerl','footerr',\n",
    "      'footnote','formfield','ftncn','ftnsep','ftnsepc','g','generator','gridtbl',\n",
    "      'header','headerf','headerl','headerr','hl','hlfr','hlinkbase','hlloc','hlsrc',\n",
    "      'hsv','htmltag','info','keycode','keywords','latentstyles','lchars','levelnumbers',\n",
    "      'leveltext','lfolevel','linkval','list','listlevel','listname','listoverride',\n",
    "      'listoverridetable','listpicture','liststylename','listtable','listtext',\n",
    "      'lsdlockedexcept','macc','maccPr','mailmerge','maln','malnScr','manager','margPr',\n",
    "      'mbar','mbarPr','mbaseJc','mbegChr','mborderBox','mborderBoxPr','mbox','mboxPr',\n",
    "      'mchr','mcount','mctrlPr','md','mdeg','mdegHide','mden','mdiff','mdPr','me',\n",
    "      'mendChr','meqArr','meqArrPr','mf','mfName','mfPr','mfunc','mfuncPr','mgroupChr',\n",
    "      'mgroupChrPr','mgrow','mhideBot','mhideLeft','mhideRight','mhideTop','mhtmltag',\n",
    "      'mlim','mlimloc','mlimlow','mlimlowPr','mlimupp','mlimuppPr','mm','mmaddfieldname',\n",
    "      'mmath','mmathPict','mmathPr','mmaxdist','mmc','mmcJc','mmconnectstr',\n",
    "      'mmconnectstrdata','mmcPr','mmcs','mmdatasource','mmheadersource','mmmailsubject',\n",
    "      'mmodso','mmodsofilter','mmodsofldmpdata','mmodsomappedname','mmodsoname',\n",
    "      'mmodsorecipdata','mmodsosort','mmodsosrc','mmodsotable','mmodsoudl',\n",
    "      'mmodsoudldata','mmodsouniquetag','mmPr','mmquery','mmr','mnary','mnaryPr',\n",
    "      'mnoBreak','mnum','mobjDist','moMath','moMathPara','moMathParaPr','mopEmu',\n",
    "      'mphant','mphantPr','mplcHide','mpos','mr','mrad','mradPr','mrPr','msepChr',\n",
    "      'mshow','mshp','msPre','msPrePr','msSub','msSubPr','msSubSup','msSubSupPr','msSup',\n",
    "      'msSupPr','mstrikeBLTR','mstrikeH','mstrikeTLBR','mstrikeV','msub','msubHide',\n",
    "      'msup','msupHide','mtransp','mtype','mvertJc','mvfmf','mvfml','mvtof','mvtol',\n",
    "      'mzeroAsc','mzeroDesc','mzeroWid','nesttableprops','nextfile','nonesttables',\n",
    "      'objalias','objclass','objdata','object','objname','objsect','objtime','oldcprops',\n",
    "      'oldpprops','oldsprops','oldtprops','oleclsid','operator','panose','password',\n",
    "      'passwordhash','pgp','pgptbl','picprop','pict','pn','pnseclvl','pntext','pntxta',\n",
    "      'pntxtb','printim','private','propname','protend','protstart','protusertbl','pxe',\n",
    "      'result','revtbl','revtim','rsidtbl','rxe','shp','shpgrp','shpinst',\n",
    "      'shppict','shprslt','shptxt','sn','sp','staticval','stylesheet','subject','sv',\n",
    "      'svb','tc','template','themedata','title','txe','ud','upr','userprops',\n",
    "      'wgrffmtfilter','windowcaption','writereservation','writereservhash','xe','xform',\n",
    "      'xmlattrname','xmlattrvalue','xmlclose','xmlname','xmlnstbl',\n",
    "      'xmlopen',\n",
    "   ))\n",
    "   # Translation of some special characters.\n",
    "   specialchars = {\n",
    "      'par': '\\n',\n",
    "      'sect': '\\n\\n',\n",
    "      'page': '\\n\\n',\n",
    "      'line': '\\n',\n",
    "      'tab': '\\t',\n",
    "      'emdash': u'\\u2014',\n",
    "      'endash': u'\\u2013',\n",
    "      'emspace': u'\\u2003',\n",
    "      'enspace': u'\\u2002',\n",
    "      'qmspace': u'\\u2005',\n",
    "      'bullet': u'\\u2022',\n",
    "      'lquote': u'\\u2018',\n",
    "      'rquote': u'\\u2019',\n",
    "      'ldblquote': u'\\201C',\n",
    "      'rdblquote': u'\\u201D', \n",
    "   }\n",
    "   stack = []\n",
    "   ignorable = False       # Whether this group (and all inside it) are \"ignorable\".\n",
    "   ucskip = 1              # Number of ASCII characters to skip after a unicode character.\n",
    "   curskip = 0             # Number of ASCII characters left to skip\n",
    "   out = []                # Output buffer.\n",
    "   for match in pattern.finditer(text):\n",
    "      word,arg,hex,char,brace,tchar = match.groups()\n",
    "      if brace:\n",
    "         curskip = 0\n",
    "         if brace == '{':\n",
    "            # Push state\n",
    "            stack.append((ucskip,ignorable))\n",
    "         elif brace == '}':\n",
    "            # Pop state\n",
    "            ucskip,ignorable = stack.pop()\n",
    "      elif char: # \\x (not a letter)\n",
    "         curskip = 0\n",
    "         if char == '~':\n",
    "            if not ignorable:\n",
    "                out.append(u'\\xA0')\n",
    "         elif char in '{}\\\\':\n",
    "            if not ignorable:\n",
    "               out.append(char)\n",
    "         elif char == '*':\n",
    "            ignorable = True\n",
    "      elif word: # \\foo\n",
    "         curskip = 0\n",
    "         if word in destinations:\n",
    "            ignorable = True\n",
    "         elif ignorable:\n",
    "            pass\n",
    "         elif word in specialchars:\n",
    "            out.append(specialchars[word])\n",
    "         elif word == 'uc':\n",
    "            ucskip = int(arg)\n",
    "         elif word == 'u':\n",
    "            c = int(arg)\n",
    "            if c < 0: c += 0x10000\n",
    "            if c > 127: out.append(chr(c))\n",
    "            else: out.append(chr(c))\n",
    "            curskip = ucskip\n",
    "      elif hex: # \\'xx\n",
    "         if curskip > 0:\n",
    "            curskip -= 1\n",
    "         elif not ignorable:\n",
    "            c = int(hex,16)\n",
    "            if c > 127: out.append(chr(c))\n",
    "            else: out.append(chr(c))\n",
    "      elif tchar:\n",
    "         if curskip > 0:\n",
    "            curskip -= 1\n",
    "         elif not ignorable:\n",
    "            out.append(tchar)\n",
    "   return ''.join(out)\n",
    "data = pd.read_csv('./train_pe.csv')\n",
    "df = pd.read_csv(\"train_pe.csv\", usecols=[2])\n",
    "for i,j in df.iterrows(): \n",
    "    text=df.Result[i]\n",
    "    df.Result[i]=striprtf(text)\n",
    "for i,j in df.iterrows(): \n",
    "    text=df.Result[i]\n",
    "    df.Result[i]=text.lower()\n",
    "to_remove = ['no', 'nor']\n",
    "new_stopwords = set(stopwords.words('english')).difference(to_remove)\n",
    "for i,j in df.iterrows():                  \n",
    "    text=df.Result[i]\n",
    "    words=text.split()\n",
    "    meaningful_words = [w for w in words if not w in new_stopwords]   \n",
    "    df.Result[i]=(\" \".join( meaningful_words))\n",
    "workabledata = pd.concat([data, df], axis=1)\n",
    "del data['Result']\n",
    "workabledata = pd.concat([data, df], axis=1)\n",
    "test_related_pe=['CT Thorax / Chest - HRCT Contrast','CT Thorax / Chest - HRCT Plain','CT Thorax / Chest - Plain','CT Whole Abdomen - Plain','CT Whole Abdomen with Contrast','CT Whole Thorax (Contrast)','CT Whole Thorax (Plain)','MRI Cholangiography (MRCP)','Ultrasound Chest','Ultrasound KUB','Ultrasound Whole Abdomen','USG Chest','USG Upper Abdomen','USG Whole Abdomen','X-ray (any Portable single exposure)','X-Ray Chest PA/AP View']\n",
    "import re\n",
    "unique_words=set()\n",
    "punctuations = list(string.punctuation)\n",
    "for i,j in workabledata.iterrows():\n",
    "    test=workabledata.TestName[i]\n",
    "    text=workabledata.Result[i]\n",
    "    if(test in test_related_pe ):\n",
    "        punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~+/='''\n",
    "        text3=\"\"\n",
    "        for char in text:\n",
    "            if char not in punctuations:\n",
    "                text3 = text3 + char\n",
    "        unique_words_temp=set(text3.split())\n",
    "        unique_words=unique_words.union(unique_words_temp)\n",
    "        df.Result[i]=text3\n",
    "workabledata = pd.concat([data, df], axis=1)\n",
    "#text=workabledata.Result[503]\n",
    "#punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~+/='''\n",
    "#text3=\"\"\n",
    "#for char in text:\n",
    "#    if char not in punctuations:\n",
    "#        text3 = text3 + char\n",
    "#text3\n",
    "#len(unique_words)\n",
    "unique_words_list=[]\n",
    "for e in unique_words:\n",
    "    #print(e)\n",
    "    unique_words_list.append(e)\n",
    "def oopsie(x):\n",
    "    flag=False\n",
    "    for i in x:\n",
    "        if(i.isdigit()):\n",
    "            flag=True\n",
    "            break\n",
    "    return flag\n",
    "li=[x for x in unique_words_list if not oopsie(x)]\n",
    "for x in li:\n",
    "    if x in new_stopwords:\n",
    "        li.remove(x)\n",
    "li.remove('kk')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "new_stopwords = set(stopwords.words('english')).difference(to_remove)\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words=new_stopwords)\n",
    "matrix = vectorizer.fit_transform(workabledata.Result)\n",
    "s=workabledata.copy()\n",
    "sd=workabledata[workabledata.Pleural_effusion>0]\n",
    "sdt=sd.copy()\n",
    "ops=1\n",
    "sd = sd.reset_index(drop=True)\n",
    "sd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "new_stopwords = set(stopwords.words('english')).difference(to_remove)\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words=new_stopwords)\n",
    "matrix = vectorizer.fit_transform(s.Result)\n",
    "matrix=matrix.toarray()\n",
    "matrix\n",
    "x=matrix\n",
    "y=s.Pleural_effusion\n",
    "yt=y.array\n",
    "bagsofwords = [Counter(re.findall(r'\\w+', txt))for txt in workabledata.Result]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.25,random_state=123)\n",
    "#algo1-Multinomial Naive Bayes\n",
    "naive = MultinomialNB()\n",
    "print(\"-------------------------------\")\n",
    "print(\"Multinomial Naive Bayes\")\n",
    "classifier = naive.fit(x_train,y_train)\n",
    "predict = classifier.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,predict)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,predict))\n",
    "print(f1_score(y_test,predict))\n",
    "print(precision_score(y_test,predict))\n",
    "print(recall_score(y_test,predict))\n",
    "#algo2-Bernoulli Naive Bayes\n",
    "print(\"-------------------------------\")\n",
    "print(\"Bernoulli Naive Bayes\")\n",
    "BernNB = BernoulliNB(binarize = 0.095)\n",
    "BernNB.fit(x_train,y_train)\n",
    "y_pred_B = BernNB.predict(x_test)\n",
    "cm = confusion_matrix(y_test,y_pred_B)\n",
    "print(cm)\n",
    "print (accuracy_score(y_test,y_pred_B))\n",
    "print (f1_score(y_test,y_pred_B))\n",
    "print(precision_score(y_test,y_pred_B))\n",
    "print(recall_score(y_test,y_pred_B))\n",
    "#algo3-Linear SVM\n",
    "clf = LinearSVC()\n",
    "clf.fit(x_train, y_train) \n",
    "y_pred_SVM=clf.predict(x_test)\n",
    "print(\"-------------------------------\")\n",
    "print(\"Linear SVC\")\n",
    "cm = confusion_matrix(y_test,y_pred_SVM)\n",
    "print(cm)\n",
    "print (accuracy_score(y_test,y_pred_SVM))\n",
    "print (f1_score(y_test,y_pred_SVM))\n",
    "print(precision_score(y_test,y_pred_SVM))\n",
    "print(recall_score(y_test,y_pred_SVM))\n",
    "#algo3-Linear SVM\n",
    "clf = svm.SVC()\n",
    "clf.fit(x_train, y_train) \n",
    "y_pred_SVM2=clf.predict(x_test)\n",
    "print(\"-------------------------------\")\n",
    "print(\"C-Support Vector Classification \")\n",
    "cm = confusion_matrix(y_test,y_pred_SVM2)\n",
    "print(cm)\n",
    "print (accuracy_score(y_test,y_pred_SVM2))\n",
    "print (f1_score(y_test,y_pred_SVM2))\n",
    "print(precision_score(y_test,y_pred_SVM2))\n",
    "print(recall_score(y_test,y_pred_SVM2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
