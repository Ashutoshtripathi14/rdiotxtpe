{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from math import *\n",
    "from numpy import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "import os\n",
    "import string\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifier</th>\n",
       "      <th>TestName</th>\n",
       "      <th>Result</th>\n",
       "      <th>Pleural_effusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>CT Thorax / Chest - HRCT Plain</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>X-ray (any Portable single exposure)</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>USG Whole Abdomen</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>Ultrasound Whole Abdomen</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17</td>\n",
       "      <td>USG Whole Abdomen</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19</td>\n",
       "      <td>USG Carotid Doppler</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20</td>\n",
       "      <td>MRI Brain (Contrast)</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21</td>\n",
       "      <td>USG Whole Abdomen</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>22</td>\n",
       "      <td>USG Whole Abdomen</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>23</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25</td>\n",
       "      <td>CT Thorax / Chest - HRCT Plain</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>26</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>27</td>\n",
       "      <td>USG KUB</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>28</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>31</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>33</td>\n",
       "      <td>USG Whole Abdomen</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>37</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>39</td>\n",
       "      <td>CT Whole Abdomen - Plain</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>41</td>\n",
       "      <td>X-ray (any Portable single exposure)</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>2842</td>\n",
       "      <td>USG Whole Abdomen</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>2843</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>2846</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>2847</td>\n",
       "      <td>USG Whole Abdomen</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2848</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2852</td>\n",
       "      <td>USG Whole Abdomen</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2853</td>\n",
       "      <td>USG Whole Abdomen</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>2854</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2858</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>2860</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2861</td>\n",
       "      <td>CT Spine-Cervical (Plain)</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>2862</td>\n",
       "      <td>X-Ray Para Nasal Sinuses [PNS]</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>2863</td>\n",
       "      <td>USG Whole Abdomen</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>2865</td>\n",
       "      <td>USG Whole Abdomen</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>2866</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>2868</td>\n",
       "      <td>USG Whole Abdomen</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>2869</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>2870</td>\n",
       "      <td>USG Whole Abdomen</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>2872</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>2873</td>\n",
       "      <td>USG Whole Abdomen</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2874</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>2878</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>2879</td>\n",
       "      <td>USG Whole Abdomen</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>2880</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>2881</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>2882</td>\n",
       "      <td>USG Whole Abdomen</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>2884</td>\n",
       "      <td>X-ray Abdomen - Erect</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>2885</td>\n",
       "      <td>X-ray Abdomen - Supine</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>2886</td>\n",
       "      <td>USG Whole Abdomen</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>2887</td>\n",
       "      <td>X-Ray Chest PA/AP View</td>\n",
       "      <td>{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2021 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Identifier                              TestName  \\\n",
       "0              2                X-Ray Chest PA/AP View   \n",
       "1              3        CT Thorax / Chest - HRCT Plain   \n",
       "2              4  X-ray (any Portable single exposure)   \n",
       "3              5                X-Ray Chest PA/AP View   \n",
       "4              6                X-Ray Chest PA/AP View   \n",
       "5              7                X-Ray Chest PA/AP View   \n",
       "6              8                X-Ray Chest PA/AP View   \n",
       "7              9                     USG Whole Abdomen   \n",
       "8             10                X-Ray Chest PA/AP View   \n",
       "9             11                X-Ray Chest PA/AP View   \n",
       "10            13                X-Ray Chest PA/AP View   \n",
       "11            14              Ultrasound Whole Abdomen   \n",
       "12            16                X-Ray Chest PA/AP View   \n",
       "13            17                     USG Whole Abdomen   \n",
       "14            18                X-Ray Chest PA/AP View   \n",
       "15            19                   USG Carotid Doppler   \n",
       "16            20                  MRI Brain (Contrast)   \n",
       "17            21                     USG Whole Abdomen   \n",
       "18            22                     USG Whole Abdomen   \n",
       "19            23                X-Ray Chest PA/AP View   \n",
       "20            25        CT Thorax / Chest - HRCT Plain   \n",
       "21            26                X-Ray Chest PA/AP View   \n",
       "22            27                               USG KUB   \n",
       "23            28                X-Ray Chest PA/AP View   \n",
       "24            30                X-Ray Chest PA/AP View   \n",
       "25            31                X-Ray Chest PA/AP View   \n",
       "26            33                     USG Whole Abdomen   \n",
       "27            37                X-Ray Chest PA/AP View   \n",
       "28            39              CT Whole Abdomen - Plain   \n",
       "29            41  X-ray (any Portable single exposure)   \n",
       "...          ...                                   ...   \n",
       "1991        2842                     USG Whole Abdomen   \n",
       "1992        2843                X-Ray Chest PA/AP View   \n",
       "1993        2846                X-Ray Chest PA/AP View   \n",
       "1994        2847                     USG Whole Abdomen   \n",
       "1995        2848                X-Ray Chest PA/AP View   \n",
       "1996        2852                     USG Whole Abdomen   \n",
       "1997        2853                     USG Whole Abdomen   \n",
       "1998        2854                X-Ray Chest PA/AP View   \n",
       "1999        2858                X-Ray Chest PA/AP View   \n",
       "2000        2860                X-Ray Chest PA/AP View   \n",
       "2001        2861             CT Spine-Cervical (Plain)   \n",
       "2002        2862        X-Ray Para Nasal Sinuses [PNS]   \n",
       "2003        2863                     USG Whole Abdomen   \n",
       "2004        2865                     USG Whole Abdomen   \n",
       "2005        2866                X-Ray Chest PA/AP View   \n",
       "2006        2868                     USG Whole Abdomen   \n",
       "2007        2869                X-Ray Chest PA/AP View   \n",
       "2008        2870                     USG Whole Abdomen   \n",
       "2009        2872                X-Ray Chest PA/AP View   \n",
       "2010        2873                     USG Whole Abdomen   \n",
       "2011        2874                X-Ray Chest PA/AP View   \n",
       "2012        2878                X-Ray Chest PA/AP View   \n",
       "2013        2879                     USG Whole Abdomen   \n",
       "2014        2880                X-Ray Chest PA/AP View   \n",
       "2015        2881                X-Ray Chest PA/AP View   \n",
       "2016        2882                     USG Whole Abdomen   \n",
       "2017        2884                 X-ray Abdomen - Erect   \n",
       "2018        2885                X-ray Abdomen - Supine   \n",
       "2019        2886                     USG Whole Abdomen   \n",
       "2020        2887                X-Ray Chest PA/AP View   \n",
       "\n",
       "                                                 Result  Pleural_effusion  \n",
       "0     {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "1     {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "2     {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "3     {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "4     {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "5     {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "6     {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "7     {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 1  \n",
       "8     {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "9     {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "10    {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "11    {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "12    {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "13    {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "14    {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 1  \n",
       "15    {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "16    {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "17    {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "18    {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "19    {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "20    {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 1  \n",
       "21    {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "22    {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "23    {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "24    {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 1  \n",
       "25    {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "26    {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 1  \n",
       "27    {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "28    {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 1  \n",
       "29    {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 1  \n",
       "...                                                 ...               ...  \n",
       "1991  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 1  \n",
       "1992  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 1  \n",
       "1993  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 1  \n",
       "1994  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 1  \n",
       "1995  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 1  \n",
       "1996  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 1  \n",
       "1997  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 1  \n",
       "1998  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 1  \n",
       "1999  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "2000  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "2001  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "2002  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "2003  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "2004  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "2005  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "2006  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "2007  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "2008  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "2009  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "2010  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "2011  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "2012  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "2013  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "2014  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "2015  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "2016  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 1  \n",
       "2017  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "2018  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "2019  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 1  \n",
       "2020  {\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fon...                 0  \n",
       "\n",
       "[2021 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./train_pe.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\\rtf1\\ansi\\ansicpg1252\\deff0\\deflang1033{\\fonttbl{\\f0\\froman\\fprq2\\fcharset0 Times New Roman;}{\\f1\\fnil\\fcharset0 Microsoft Sans Serif;}}\r\n",
      "{\\colortbl ;\\red0\\green0\\blue0;}\r\n",
      "{\\stylesheet{ Normal;}{\\s1 heading 1;}{\\s2 heading 2;}}\r\n",
      "\\viewkind4\\uc1\\pard\\keepn\\s2\\cf1\\b\\f0\\fs21 Investigation: X-Ray - Chest (Portable) \\par\r\n",
      "\\par\r\n",
      "\\pard Results:\\b0\\par\r\n",
      "\\par\r\n",
      "Heterogeneous opacity seen in left upper and mid zones with shifting of trachea towards left and left hila superiorly - s/o left upper lobe collapse.\n",
      "-----\n",
      "\\par\r\n",
      "\\par\r\n",
      "Right lung appears unremarkable.\n",
      "-----\n",
      "\\par\r\n",
      "\\par\r\n",
      "CP angles and domes of the diaphragm are normal.\\par\r\n",
      "\\par\r\n",
      "Cardiac size and configuration is normal.\\par\r\n",
      "\\par\r\n",
      "Please correlate clinically.\n",
      "-----\n",
      "\\par\r\n",
      "\\cf0\\f1\\fs17\\par\r\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import nltk.data\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "data = data.Result[0]\n",
    "print (\"\\n-----\\n\".join(tokenizer.tokenize(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-45d94c67e925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-047ed65ff157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'Result'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2635e90c4c58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'Result'"
     ]
    }
   ],
   "source": [
    "data.Result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def striprtf(text):\n",
    "   pattern = re.compile(r\"\\\\([a-z]{1,32})(-?\\d{1,10})?[ ]?|\\\\'([0-9a-f]{2})|\\\\([^a-z])|([{}])|[\\r\\n]+|(.)\", re.I)\n",
    "   # control words which specify a \"destionation\".\n",
    "   destinations = frozenset((\n",
    "      'aftncn','aftnsep','aftnsepc','annotation','atnauthor','atndate','atnicn','atnid',\n",
    "      'atnparent','atnref','atntime','atrfend','atrfstart','author','background',\n",
    "      'bkmkend','bkmkstart','blipuid','buptim','category','colorschememapping',\n",
    "      'colortbl','comment','company','creatim','datafield','datastore','defchp','defpap',\n",
    "      'do','doccomm','docvar','dptxbxtext','ebcend','ebcstart','factoidname','falt',\n",
    "      'fchars','ffdeftext','ffentrymcr','ffexitmcr','ffformat','ffhelptext','ffl',\n",
    "      'ffname','ffstattext','field','file','filetbl','fldinst','fldrslt','fldtype',\n",
    "      'fname','fontemb','fontfile','fonttbl','footer','footerf','footerl','footerr',\n",
    "      'footnote','formfield','ftncn','ftnsep','ftnsepc','g','generator','gridtbl',\n",
    "      'header','headerf','headerl','headerr','hl','hlfr','hlinkbase','hlloc','hlsrc',\n",
    "      'hsv','htmltag','info','keycode','keywords','latentstyles','lchars','levelnumbers',\n",
    "      'leveltext','lfolevel','linkval','list','listlevel','listname','listoverride',\n",
    "      'listoverridetable','listpicture','liststylename','listtable','listtext',\n",
    "      'lsdlockedexcept','macc','maccPr','mailmerge','maln','malnScr','manager','margPr',\n",
    "      'mbar','mbarPr','mbaseJc','mbegChr','mborderBox','mborderBoxPr','mbox','mboxPr',\n",
    "      'mchr','mcount','mctrlPr','md','mdeg','mdegHide','mden','mdiff','mdPr','me',\n",
    "      'mendChr','meqArr','meqArrPr','mf','mfName','mfPr','mfunc','mfuncPr','mgroupChr',\n",
    "      'mgroupChrPr','mgrow','mhideBot','mhideLeft','mhideRight','mhideTop','mhtmltag',\n",
    "      'mlim','mlimloc','mlimlow','mlimlowPr','mlimupp','mlimuppPr','mm','mmaddfieldname',\n",
    "      'mmath','mmathPict','mmathPr','mmaxdist','mmc','mmcJc','mmconnectstr',\n",
    "      'mmconnectstrdata','mmcPr','mmcs','mmdatasource','mmheadersource','mmmailsubject',\n",
    "      'mmodso','mmodsofilter','mmodsofldmpdata','mmodsomappedname','mmodsoname',\n",
    "      'mmodsorecipdata','mmodsosort','mmodsosrc','mmodsotable','mmodsoudl',\n",
    "      'mmodsoudldata','mmodsouniquetag','mmPr','mmquery','mmr','mnary','mnaryPr',\n",
    "      'mnoBreak','mnum','mobjDist','moMath','moMathPara','moMathParaPr','mopEmu',\n",
    "      'mphant','mphantPr','mplcHide','mpos','mr','mrad','mradPr','mrPr','msepChr',\n",
    "      'mshow','mshp','msPre','msPrePr','msSub','msSubPr','msSubSup','msSubSupPr','msSup',\n",
    "      'msSupPr','mstrikeBLTR','mstrikeH','mstrikeTLBR','mstrikeV','msub','msubHide',\n",
    "      'msup','msupHide','mtransp','mtype','mvertJc','mvfmf','mvfml','mvtof','mvtol',\n",
    "      'mzeroAsc','mzeroDesc','mzeroWid','nesttableprops','nextfile','nonesttables',\n",
    "      'objalias','objclass','objdata','object','objname','objsect','objtime','oldcprops',\n",
    "      'oldpprops','oldsprops','oldtprops','oleclsid','operator','panose','password',\n",
    "      'passwordhash','pgp','pgptbl','picprop','pict','pn','pnseclvl','pntext','pntxta',\n",
    "      'pntxtb','printim','private','propname','protend','protstart','protusertbl','pxe',\n",
    "      'result','revtbl','revtim','rsidtbl','rxe','shp','shpgrp','shpinst',\n",
    "      'shppict','shprslt','shptxt','sn','sp','staticval','stylesheet','subject','sv',\n",
    "      'svb','tc','template','themedata','title','txe','ud','upr','userprops',\n",
    "      'wgrffmtfilter','windowcaption','writereservation','writereservhash','xe','xform',\n",
    "      'xmlattrname','xmlattrvalue','xmlclose','xmlname','xmlnstbl',\n",
    "      'xmlopen',\n",
    "   ))\n",
    "   # Translation of some special characters.\n",
    "   specialchars = {\n",
    "      'par': '\\n',\n",
    "      'sect': '\\n\\n',\n",
    "      'page': '\\n\\n',\n",
    "      'line': '\\n',\n",
    "      'tab': '\\t',\n",
    "      'emdash': u'\\u2014',\n",
    "      'endash': u'\\u2013',\n",
    "      'emspace': u'\\u2003',\n",
    "      'enspace': u'\\u2002',\n",
    "      'qmspace': u'\\u2005',\n",
    "      'bullet': u'\\u2022',\n",
    "      'lquote': u'\\u2018',\n",
    "      'rquote': u'\\u2019',\n",
    "      'ldblquote': u'\\201C',\n",
    "      'rdblquote': u'\\u201D', \n",
    "   }\n",
    "   stack = []\n",
    "   ignorable = False       # Whether this group (and all inside it) are \"ignorable\".\n",
    "   ucskip = 1              # Number of ASCII characters to skip after a unicode character.\n",
    "   curskip = 0             # Number of ASCII characters left to skip\n",
    "   out = []                # Output buffer.\n",
    "   for match in pattern.finditer(text):\n",
    "      word,arg,hex,char,brace,tchar = match.groups()\n",
    "      if brace:\n",
    "         curskip = 0\n",
    "         if brace == '{':\n",
    "            # Push state\n",
    "            stack.append((ucskip,ignorable))\n",
    "         elif brace == '}':\n",
    "            # Pop state\n",
    "            ucskip,ignorable = stack.pop()\n",
    "      elif char: # \\x (not a letter)\n",
    "         curskip = 0\n",
    "         if char == '~':\n",
    "            if not ignorable:\n",
    "                out.append(u'\\xA0')\n",
    "         elif char in '{}\\\\':\n",
    "            if not ignorable:\n",
    "               out.append(char)\n",
    "         elif char == '*':\n",
    "            ignorable = True\n",
    "      elif word: # \\foo\n",
    "         curskip = 0\n",
    "         if word in destinations:\n",
    "            ignorable = True\n",
    "         elif ignorable:\n",
    "            pass\n",
    "         elif word in specialchars:\n",
    "            out.append(specialchars[word])\n",
    "         elif word == 'uc':\n",
    "            ucskip = int(arg)\n",
    "         elif word == 'u':\n",
    "            c = int(arg)\n",
    "            if c < 0: c += 0x10000\n",
    "            if c > 127: out.append(chr(c))\n",
    "            else: out.append(chr(c))\n",
    "            curskip = ucskip\n",
    "      elif hex: # \\'xx\n",
    "         if curskip > 0:\n",
    "            curskip -= 1\n",
    "         elif not ignorable:\n",
    "            c = int(hex,16)\n",
    "            print(c)\n",
    "            if c > 127: out.append(chr(c))\n",
    "            else: out.append(chr(c))\n",
    "      elif tchar:\n",
    "         if curskip > 0:\n",
    "            curskip -= 1\n",
    "         elif not ignorable:\n",
    "            out.append(tchar)\n",
    "   return ''.join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_pe.csv\", usecols=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "216\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n",
      "183\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>investigation: x-ray - chest (portable) result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hrct chest (non contrast) spiral scanning thor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chest x-ray pa view no significant interval ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>investigation: x-ray - chest ap (portable) vie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x-ray chest pa/ap view 26-aug-2017: results: r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>x-ray chest pa/ap view 28-aug-2017: results: r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>x-ray chest pa/ap view 22-aug-2017: results: c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>usg whole abdomen 22-aug-2017: liver: normal s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>x-ray chest pa/ap view 23-aug-2017: results: c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>x-ray chest pa/ap view 21-aug-2017: results: n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>investigation: x-ray - chest pa view results: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>results: liver normal size, shape echogenicity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>investigation: x-ray - chest pa view results: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>usg whole abdomen liver normal size, shape, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>chest x-ray bilateral lungs show prominent bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>carotid vessels neck evaluated grey scale, col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>report mri brain. technique:- sagittal t2w; ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>liver normal size &amp;, shape, contour shows norm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>liver normal size , shape , contour shows incr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>investigation: x-ray - chest pa view results: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ct thorax / chest - hrct plain 14-jul-2017: re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>x-ray chest pa/ap view 19-jul-2017: results: s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>usg kub 14-jul-2017: suboptimal portable bedsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>x-ray chest ap view 13-jul-2017: results: ster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>central line, et ng tubes seen situ. non homog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rotation + central line, et ng tubes seen situ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>usg - whole abdomen chest (bedside) liver enla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>chest x-ray - portable follow case. central li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ncct scan chest whole abdomen spiral scanning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>investigation: x-ray - chest ap (portable) vie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>investigation : ultrasound whole abdomen resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>investigation: x-ray chest ap supine (portable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>investigation: x-ray chest ap supine (portable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>investigation: ultrasound whole abdomen result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>investigation: x-ray chest ap supine (portable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>investigation : ultrasound whole abdomen resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>investigation : ultrasound whole abdomen resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>x-ray chest pa/ap view 18-aug-2017: results: r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>x-ray chest pa/ap view 10-jun-2017: results: n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>x-ray chest pa/ap view 01-jul-2017: subcutaneo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>ct spine-cervical (plain) 01-jul-2017: results...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>x-ray para nasal sinuses [pns] 28-aug-2017: re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>usg whole abdomen 29-aug-2017: results: liver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>usg whole abdomen 19-jul-2017: results: liver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>x-ray chest pa/ap view 19-jul-2017: results: n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>usg whole abdomen 20-jul-2017: results: liver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>x-ray chest pa/ap view 24-jul-2017: results: n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>usg whole abdomen 24-jul-2017: results: liver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>x-ray chest pa/ap view 30-jul-2017: results: n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>usg whole abdomen 21-aug-2017: results: liver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>x-ray chest pa/ap view 21-aug-2017: results: n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>x-ray chest pa/ap view 17-aug-2017: results: n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>investigation : ultrasound whole abdomen resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>x-ray chest pa/ap view 21-aug-2017: results: n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>x-ray chest pa/ap view 26-aug-2017: diffuse ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>investigation: ultrasound whole abdomen result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>investigation : x-ray abdomen erect results : ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>investigation : x-ray abdomen erect / supine r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>usg whole abdomen 29-aug-2017: (female) invest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>x-ray chest pa view 29-aug-2017: results: no f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2021 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Result\n",
       "0     investigation: x-ray - chest (portable) result...\n",
       "1     hrct chest (non contrast) spiral scanning thor...\n",
       "2     chest x-ray pa view no significant interval ch...\n",
       "3     investigation: x-ray - chest ap (portable) vie...\n",
       "4     x-ray chest pa/ap view 26-aug-2017: results: r...\n",
       "5     x-ray chest pa/ap view 28-aug-2017: results: r...\n",
       "6     x-ray chest pa/ap view 22-aug-2017: results: c...\n",
       "7     usg whole abdomen 22-aug-2017: liver: normal s...\n",
       "8     x-ray chest pa/ap view 23-aug-2017: results: c...\n",
       "9     x-ray chest pa/ap view 21-aug-2017: results: n...\n",
       "10    investigation: x-ray - chest pa view results: ...\n",
       "11    results: liver normal size, shape echogenicity...\n",
       "12    investigation: x-ray - chest pa view results: ...\n",
       "13    usg whole abdomen liver normal size, shape, co...\n",
       "14    chest x-ray bilateral lungs show prominent bro...\n",
       "15    carotid vessels neck evaluated grey scale, col...\n",
       "16    report mri brain. technique:- sagittal t2w; ax...\n",
       "17    liver normal size &, shape, contour shows norm...\n",
       "18    liver normal size , shape , contour shows incr...\n",
       "19    investigation: x-ray - chest pa view results: ...\n",
       "20    ct thorax / chest - hrct plain 14-jul-2017: re...\n",
       "21    x-ray chest pa/ap view 19-jul-2017: results: s...\n",
       "22    usg kub 14-jul-2017: suboptimal portable bedsi...\n",
       "23    x-ray chest ap view 13-jul-2017: results: ster...\n",
       "24    central line, et ng tubes seen situ. non homog...\n",
       "25    rotation + central line, et ng tubes seen situ...\n",
       "26    usg - whole abdomen chest (bedside) liver enla...\n",
       "27    chest x-ray - portable follow case. central li...\n",
       "28    ncct scan chest whole abdomen spiral scanning ...\n",
       "29    investigation: x-ray - chest ap (portable) vie...\n",
       "...                                                 ...\n",
       "1991  investigation : ultrasound whole abdomen resul...\n",
       "1992  investigation: x-ray chest ap supine (portable...\n",
       "1993  investigation: x-ray chest ap supine (portable...\n",
       "1994  investigation: ultrasound whole abdomen result...\n",
       "1995  investigation: x-ray chest ap supine (portable...\n",
       "1996  investigation : ultrasound whole abdomen resul...\n",
       "1997  investigation : ultrasound whole abdomen resul...\n",
       "1998  x-ray chest pa/ap view 18-aug-2017: results: r...\n",
       "1999  x-ray chest pa/ap view 10-jun-2017: results: n...\n",
       "2000  x-ray chest pa/ap view 01-jul-2017: subcutaneo...\n",
       "2001  ct spine-cervical (plain) 01-jul-2017: results...\n",
       "2002  x-ray para nasal sinuses [pns] 28-aug-2017: re...\n",
       "2003  usg whole abdomen 29-aug-2017: results: liver ...\n",
       "2004  usg whole abdomen 19-jul-2017: results: liver ...\n",
       "2005  x-ray chest pa/ap view 19-jul-2017: results: n...\n",
       "2006  usg whole abdomen 20-jul-2017: results: liver ...\n",
       "2007  x-ray chest pa/ap view 24-jul-2017: results: n...\n",
       "2008  usg whole abdomen 24-jul-2017: results: liver ...\n",
       "2009  x-ray chest pa/ap view 30-jul-2017: results: n...\n",
       "2010  usg whole abdomen 21-aug-2017: results: liver ...\n",
       "2011  x-ray chest pa/ap view 21-aug-2017: results: n...\n",
       "2012  x-ray chest pa/ap view 17-aug-2017: results: n...\n",
       "2013  investigation : ultrasound whole abdomen resul...\n",
       "2014  x-ray chest pa/ap view 21-aug-2017: results: n...\n",
       "2015  x-ray chest pa/ap view 26-aug-2017: diffuse ri...\n",
       "2016  investigation: ultrasound whole abdomen result...\n",
       "2017  investigation : x-ray abdomen erect results : ...\n",
       "2018  investigation : x-ray abdomen erect / supine r...\n",
       "2019  usg whole abdomen 29-aug-2017: (female) invest...\n",
       "2020  x-ray chest pa view 29-aug-2017: results: no f...\n",
       "\n",
       "[2021 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i,j in df.iterrows(): \n",
    "    text=df.Result[i]\n",
    "    df.Result[i]=striprtf(text)\n",
    "for i,j in df.iterrows(): \n",
    "    text=df.Result[i]\n",
    "    df.Result[i]=text.lower()\n",
    "to_remove = ['no', 'nor']\n",
    "new_stopwords = set(stopwords.words('english')).difference(to_remove)\n",
    "for i,j in df.iterrows():                  \n",
    "    text=df.Result[i]\n",
    "    words=text.split()\n",
    "    meaningful_words = [w for w in words if not w in new_stopwords]   \n",
    "    df.Result[i]=(\" \".join( meaningful_words))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type \"<class 'str'>\"; only pd.Series, pd.DataFrame, and pd.Panel (deprecated) objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f2804aae3776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mworkabledata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    226\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                        copy=copy, sort=sort)\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    287\u001b[0m                        \u001b[0;34m' only pd.Series, pd.DataFrame, and pd.Panel'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                        ' (deprecated) objs are valid'.format(type(obj)))\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type \"<class 'str'>\"; only pd.Series, pd.DataFrame, and pd.Panel (deprecated) objs are valid"
     ]
    }
   ],
   "source": [
    "workabledata = pd.concat([data, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\\\rtf1\\\\ansi\\\\ansicpg1252\\\\deff0\\\\deflang1033{\\\\fonttbl{\\\\f0\\\\froman\\\\fprq2\\\\fcharset0 Times New Roman;}{\\\\f1\\\\fnil\\\\fcharset0 Microsoft Sans Serif;}}\\r\\n{\\\\colortbl ;\\\\red0\\\\green0\\\\blue0;}\\r\\n{\\\\stylesheet{ Normal;}{\\\\s1 heading 1;}{\\\\s2 heading 2;}}\\r\\n\\\\viewkind4\\\\uc1\\\\pard\\\\keepn\\\\s2\\\\cf1\\\\b\\\\f0\\\\fs21 Investigation: X-Ray - Chest (Portable) \\\\par\\r\\n\\\\par\\r\\n\\\\pard Results:\\\\b0\\\\par\\r\\n\\\\par\\r\\nHeterogeneous opacity seen in left upper and mid zones with shifting of trachea towards left and left hila superiorly - s/o left upper lobe collapse. \\\\par\\r\\n\\\\par\\r\\nRight lung appears unremarkable. \\\\par\\r\\n\\\\par\\r\\nCP angles and domes of the diaphragm are normal.\\\\par\\r\\n\\\\par\\r\\nCardiac size and configuration is normal.\\\\par\\r\\n\\\\par\\r\\nPlease correlate clinically. \\\\par\\r\\n\\\\cf0\\\\f1\\\\fs17\\\\par\\r\\n}\\r\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type \"<class 'str'>\"; only pd.Series, pd.DataFrame, and pd.Panel (deprecated) objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f2804aae3776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mworkabledata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    226\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                        copy=copy, sort=sort)\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    287\u001b[0m                        \u001b[0;34m' only pd.Series, pd.DataFrame, and pd.Panel'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                        ' (deprecated) objs are valid'.format(type(obj)))\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type \"<class 'str'>\"; only pd.Series, pd.DataFrame, and pd.Panel (deprecated) objs are valid"
     ]
    }
   ],
   "source": [
    "workabledata = pd.concat([data, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'workabledata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-dca8a680499d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mworkabledata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'workabledata' is not defined"
     ]
    }
   ],
   "source": [
    "workabledata.Result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workabledata.groupby(['TestName']).count().sort_values(['Identifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " workabledata.to_csv(\"workablehopefuk.csv\", index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workabledata.to_excel(\"workablehopefukes.xlsx\", sheet_name=\"Sheet 1\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workabledata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_related_pe=['CT Thorax / Chest - HRCT Contrast','CT Thorax / Chest - HRCT Plain','CT Thorax / Chest - Plain','CT Whole Abdomen - Plain','CT Whole Abdomen with Contrast','CT Whole Thorax (Contrast)','CT Whole Thorax (Plain)','MRI Cholangiography (MRCP)','Ultrasound Chest','Ultrasound KUB','Ultrasound Whole Abdomen','USG Chest','USG Upper Abdomen','USG Whole Abdomen','X-ray (any Portable single exposure)','X-Ray Chest PA/AP View']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "unique_words=set()\n",
    "punctuations = list(string.punctuation)\n",
    "for i,j in workabledata.iterrows():\n",
    "    test=workabledata.TestName[i]\n",
    "    text=workabledata.Result[i]\n",
    "    if(test in test_related_pe ):\n",
    "        punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~+/='''\n",
    "        text3=\"\"\n",
    "        for char in text:\n",
    "            if char not in punctuations:\n",
    "                text3 = text3 + char\n",
    "        unique_words_temp=set(text3.split())\n",
    "        unique_words=unique_words.union(unique_words_temp)\n",
    "        \n",
    "        \n",
    "#text=workabledata.Result[503]\n",
    "#punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~+/='''\n",
    "#text3=\"\"\n",
    "#for char in text:\n",
    "#    if char not in punctuations:\n",
    "#        text3 = text3 + char\n",
    "#text3\n",
    "#len(unique_words)\n",
    "unique_words_list=[]\n",
    "for e in unique_words:\n",
    "    #print(e)\n",
    "    unique_words_list.append(e)\n",
    "unique_words_list\n",
    "def oopsie(x):\n",
    "    flag=False\n",
    "    for i in x:\n",
    "        if(i.isdigit()):\n",
    "            flag=True\n",
    "            break\n",
    "    return flag\n",
    "li=[x for x in unique_words_list if not oopsie(x)]\n",
    "sorted(li)\n",
    "len(li)\n",
    "for x in li:\n",
    "    if x in new_stopwords:\n",
    "        li.remove(x)\n",
    "len(li)\n",
    "li.remove('kk')\n",
    "li\n",
    "workabledata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "new_stopwords = set(stopwords.words('english')).difference(to_remove)\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words=new_stopwords)\n",
    "matrix = vectorizer.fit_transform(workabledata.Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=workabledata.copy()\n",
    "sd=workabledata[workabledata.Pleural_effusion>0]\n",
    "sdt=sd.copy()\n",
    "ops=1\n",
    "sd = sd.reset_index(drop=True)\n",
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "top_N = 20\n",
    "\n",
    "txt = sd.Result.str.lower().str.replace(r'\\|', ' ').str.cat(sep=' ')\n",
    "#print(txt)\n",
    "\n",
    "words = nltk.tokenize.word_tokenize(txt)\n",
    "\n",
    "word_dist = nltk.FreqDist(words)\n",
    "\n",
    "words_except_stop_dist = nltk.FreqDist(w for w in words if (w not in new_stopwords and w not in string.punctuation and w!='.') ) \n",
    "\n",
    "#print('All frequencies, including STOPWORDS:')\n",
    "#print('=' * 60)\n",
    "#rslt = pd.DataFrame(word_dist.most_common(top_N),\n",
    "#                    columns=['Word', 'Frequency'])\n",
    "#print(rslt)\n",
    "#print('=' * 60)\n",
    "\n",
    "rslt = pd.DataFrame(words_except_stop_dist.most_common(top_N),\n",
    "                    columns=['Word', 'Frequency']).set_index('Word')\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "#rslt.plot.bar(rot=0)\n",
    "word_counter = Counter(words_except_stop_dist)\n",
    "words\n",
    "oofsd=Counter(nltk.bigrams(words))\n",
    "#print(oofsd)\n",
    "oofsd.most_common()\n",
    "oofsdf=[]\n",
    "for x in oofsd:\n",
    "    txt=x\n",
    "    if(txt[0]=='no'):\n",
    "        #print(txt)\n",
    "        oofsdf.append(txt)\n",
    "oofsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "twword=[('mid','zones'),('pleural', 'effusion'),('right', 'lobe'),('lower', 'lobe'),('middle', 'lobe'),('upper', 'lobe'),('left', 'lobe'),('right', 'side'),('left', 'side'),('left', 'kidney'),('right', 'kidney'),('wall', 'thickening'),('bilateral', 'kidneys'),('focal', 'lesion'),('urinary', 'bladder'),('gall', 'bladder'),('mass', 'seen'),('wall', 'oedema'),('lymph', 'nodes'),('thick', 'walled'),('free', 'fluid'),('soft', 'tissues'),('bladder', 'wall')]\n",
    "thrword=[('left', 'upper_lobe'),('right', 'upper_lobe'),('right','pleural_effusion'),('gall_bladder', 'walls'),('left', 'pleural_effusion')]\n",
    "to2=[]\n",
    "s\n",
    "for i,j in s.iterrows():\n",
    "    text=s.Result[i]\n",
    "    to=nltk.tokenize.word_tokenize(text)\n",
    "    oof=[]\n",
    "    for x in range(len(to)-1):\n",
    "        a=(to[x],to[x+1])\n",
    "        if(a in twword):\n",
    "            oof.append(x)\n",
    "    for x in oof:\n",
    "        a=to[x]+'_'+to[x+1]\n",
    "        to[x]=a\n",
    "        to[x+1]=''\n",
    "\n",
    "    oof2=[]\n",
    "    for x in range(len(to)-1):\n",
    "        a=(to[x],to[x+1])\n",
    "        if(a in thrword):\n",
    "            #print(a)\n",
    "            oof2.append(x)\n",
    "            #print(a)\n",
    "        #print(len(oof2))\n",
    "    for x in oof2:\n",
    "        a=to[x]+'_'+to[x+1]\n",
    "        to[x]=a\n",
    "        to[x+1]=''\n",
    "    oof3=[]\n",
    "    for x in range(len(to)-1):\n",
    "        a=(to[x],to[x+1])\n",
    "        if(a in oofsdf):\n",
    "            #print(a)\n",
    "            oof3.append(x)\n",
    "            #print(a)\n",
    "        #print(len(oof3))\n",
    "    for x in oof3:\n",
    "        a=to[x]+'_'+to[x+1]\n",
    "        to[x]=a\n",
    "        to[x+1]=''\n",
    "    #print(to)\n",
    "    #to2=to2+to\n",
    "    #print(len(to))\n",
    "    for x in to:\n",
    "        if(x==''):\n",
    "            to.remove(x)\n",
    "    txt=' '.join(to)\n",
    "    df.Result[i]=txt\n",
    "    \n",
    "#s=pd.concat([s,df],axis=1)\n",
    "#workabledata = pd.concat([data, df], axis=1)\n",
    "#workabledata.Result[]\n",
    "    #print(txt)\n",
    "#len(to2)\n",
    "\n",
    "#xd=Counter(to2)\n",
    "#xd.most_common()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer \n",
    "ps = PorterStemmer() \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "for i,j in s.iterrows():\n",
    "    text=s.Result[i]\n",
    "    to=nltk.tokenize.word_tokenize(text)\n",
    "    #print(to)\n",
    "    for x in range (len(to)):\n",
    "        y=to[x]\n",
    "        to[x]=lemmatizer.lemmatize(y)\n",
    "        to[x]=ps.stem(to[x])\n",
    "        \n",
    "    #print(to)\n",
    "        #print(x)\n",
    "    txt=' '.join(to)\n",
    "    print(txt)\n",
    "    df.Result[i]=txt\n",
    "    #print(to)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "new_stopwords = set(stopwords.words('english')).difference(to_remove)\n",
    "matrix = vectorizer.fit_transform(to2)\n",
    "matrix=matrix.toarray()\n",
    "#sorted_word_counts = sorted(list(word_counter.values()), reverse=True)\n",
    "#plt.loglog(sorted_word_counts)\n",
    "#plt.ylabel(\"Freq\")\n",
    "#plt.xlabel(\"Word Rank\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#s=pd.concat([s,df],axis=1)\n",
    "#del s['Result']\n",
    "#s=pd.concat([s,df],axis=1)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(sorted_word_counts, bins=1623, log=True);\n",
    "import gensim\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "lda=LDA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "new_stopwords = set(stopwords.words('english')).difference(to_remove)\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words=new_stopwords)\n",
    "#matrix = vectorizer.fit_transform(to2)\n",
    "#matrix=matrix.toarray()\n",
    "matrix = vectorizer.fit_transform(s.Result)\n",
    "m2=vectorizer.fit_transform(text.split())\n",
    "m2t=m2.toarray()\n",
    "print(m2t)\n",
    "m2t.resize(matrix.shape)\n",
    "matrix=matrix.toarray()\n",
    "print(matrix)\n",
    "matrix\n",
    "#print(len(matrix))\n",
    "x=matrix\n",
    "print(m2t.shape)\n",
    "print(x.shape)\n",
    "y=s.Pleural_effusion\n",
    "yt=y.array\n",
    "x.shape\n",
    "myList = list(nltk.bigrams(words))\n",
    "for i in myList:\n",
    "    if i[0]=='normal':\n",
    "        myList.remove(i)\n",
    "for i in myList:\n",
    "    if i[1]=='normal':\n",
    "        myList.remove(i) \n",
    "myList2no=[]\n",
    "for i in myList:\n",
    "    if i[0]=='no':\n",
    "        myList2no.append(i)\n",
    "        myList.remove(i)\n",
    "myListnod=Counter(myList2no)\n",
    "myListnos=myListnod.most_common()\n",
    "#for i in myListdfg:\n",
    "    #if(i[1]==1):\n",
    "        #myList.remove(i[0])\n",
    "myListsd=Counter(myList)\n",
    "myListdfg=myListsd.most_common()\n",
    "(myListdfg)\n",
    "print(len(myListdfg))\n",
    "print(len(myListnos))\n",
    "(myList)\n",
    "twword=[('right', 'lobe'),('left', 'lobe'),('right', 'side'),('left', 'side'),('mass', 'seen'),('wall', 'oedema'),('lymph', 'nodes'),('thick', 'walled'),('free', 'fluid'),('soft', 'tissues'),('bladder', 'wall')]\n",
    "thrword=[('left', 'upper','lobe'),('right', 'upper','lobe'),('left', 'kidney'),('right', 'kidney'),('wall', 'thickening'),('bilateral', 'kidneys'),('focal', 'lesion'),('urinary', 'bladder'),('gall', 'bladder'),('pleural', 'effusion'),('right', 'pleural', 'effusion'),('gall', 'bladder', 'walls'),('left', 'pleural', 'effusion')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter_list=[word_counter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagsofwords = [Counter(re.findall(r'\\w+', txt))for txt in workabledata.Result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "len(bagsofwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score,recall_score,precision_score\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.25,random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lda=lda.fit(x_train,y_train).transform(x_train)\n",
    "x_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "plt.figure(figsize=(35,20))\n",
    "plt.scatter(x_lda[:,0],x_lda[:,1],c='Blue',s=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive = MultinomialNB()\n",
    "classifier = naive.fit(x_train,y_train)\n",
    "predict = classifier.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,predict)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = cm.trace()/cm.sum()\n",
    "print(accuracy)\n",
    "print(f1_score(y_test,predict))\n",
    "print(precision_score(y_test,predict))\n",
    "print(recall_score(y_test,predict))\n",
    "print(roc_auc_score(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BernNB = BernoulliNB(binarize = 0.095)\n",
    "BernNB.fit(x_train,y_train)\n",
    "print(BernNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_B = BernNB.predict(x_test)\n",
    "print (accuracy_score(y_test,y_pred_B))\n",
    "print (f1_score(y_test,y_pred_B))\n",
    "print(precision_score(y_test,y_pred_B))\n",
    "print(recall_score(y_test,y_pred_B))\n",
    "print(roc_auc_score(y_test,y_pred_B))\n",
    "cm = confusion_matrix(y_test,y_pred_B)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = svm.LinearSVC()\n",
    "clf.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_SVM=clf.predict(x_test)\n",
    "#y_pred_SVM\n",
    "print (accuracy_score(y_test,y_pred_SVM))\n",
    "print (f1_score(y_test,y_pred_SVM))\n",
    "print(precision_score(y_test,y_pred_SVM))\n",
    "print(recall_score(y_test,y_pred_SVM))\n",
    "print(roc_auc_score(y_test,y_pred_SVM))\n",
    "plt.figure(figsize=(35,20))\n",
    "plt.scatter(pca_2d[:,0],pca_2d[:,1],c=\"Blue\",s=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = svm.LinearSVC()\n",
    "clf.fit(matrix, y)\n",
    "y_pred_SVM2=clf.predict([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred_SVM)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2).fit(x_train)\n",
    "pca_2d = pca.fit(x_train).transform(x_train)\n",
    "plt.figure(figsize=(35,20))\n",
    "plt.scatter(pca_2d[:,0],pca_2d[:,1],c=\"Blue\",s=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img=pca.transform(x_test)\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lor=LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lor.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ospdo=lor.predict(x_test)\n",
    "print (accuracy_score(y_test,ospdo))\n",
    "print (f1_score(y_test,ospdo))\n",
    "print(precision_score(y_test,ospdo))\n",
    "print(recall_score(y_test,ospdo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "probs=lor.predict(x_test)\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oofd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(x_train, y_train)\n",
    "# predict probabilities\n",
    "probs = model.predict_proba(x_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
